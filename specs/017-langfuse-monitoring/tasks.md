# Tasks: –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ LLM —á–µ—Ä–µ–∑ Langfuse

**Input**: Design documents from `/specs/017-langfuse-monitoring/`
**Prerequisites**: plan.md, spec.md, research.md, data-model.md, quickstart.md

**Tests**: –ù–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Å—Ç–æ–≤ ‚Äî —ç—Ç–æ –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–Ω–∞—è/observability —Ñ–∏—á–∞. –ü—Ä–æ–≤–µ—Ä—è–µ—Ç—Å—è —Ä—É—á–Ω—ã–º smoke-—Ç–µ—Å—Ç–æ–º –∏ –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–µ–π —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Ç–µ—Å—Ç–æ–≤.

**Organization**: Tasks are grouped by user story to enable independent implementation and testing of each story.

## Format: `[ID] [P?] [Story] Description`

- **[P]**: Can run in parallel (different files, no dependencies)
- **[Story]**: Which user story this task belongs to (e.g., US1, US2, US3, US4)
- Include exact file paths in descriptions

## Phase 1: Setup (Shared Infrastructure)

**Purpose**: Dependencies, configuration, and env vars shared across all user stories

- [x] T001 [P] Add `langfuse` dependency to `backend/requirements.txt`
- [x] T002 [P] Add Langfuse settings (LANGFUSE_SECRET_KEY, LANGFUSE_PUBLIC_KEY, LANGFUSE_HOST, LANGFUSE_TRACING_ENABLED) to `backend/app/config.py`
- [x] T003 [P] Add Langfuse configuration section to `.env.example` with dev defaults

---

## Phase 2: User Story 3 ‚Äî Langfuse –∫–∞–∫ —á–∞—Å—Ç—å –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã (Priority: P1) üéØ MVP

**Goal**: `docker compose up` –∑–∞–ø—É—Å–∫–∞–µ—Ç Langfuse —Å–æ –≤—Å–µ–π –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π –±–µ–∑ —Ä—É—á–Ω–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏

**Independent Test**: –í—ã–ø–æ–ª–Ω–∏—Ç—å `docker compose up -d`, –¥–æ–∂–¥–∞—Ç—å—Å—è —Å—Ç–∞—Ä—Ç–∞ –≤—Å–µ—Ö –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤, –æ—Ç–∫—Ä—ã—Ç—å http://localhost:3000 –∏ —É–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ Langfuse UI –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è

**‚ö†Ô∏è CRITICAL**: –ë–µ–∑ —Ä–∞–±–æ—Ç–∞—é—â–µ–π –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã Langfuse –Ω–µ–≤–æ–∑–º–æ–∂–Ω—ã US1, US2, US4

### Implementation for User Story 3

- [x] T004 [US3] Add 6 Langfuse service definitions (langfuse-web, langfuse-worker, langfuse-postgres, langfuse-clickhouse, langfuse-redis, langfuse-minio) with healthchecks to `docker-compose.yml`
- [x] T005 [US3] Add 4 Langfuse persistent volumes (langfuse_postgres_data, langfuse_clickhouse_data, langfuse_clickhouse_logs, langfuse_minio_data) to `docker-compose.yml`
- [x] T006 [US3] Configure auto-provisioning env vars (LANGFUSE_INIT_ORG_*, LANGFUSE_INIT_PROJECT_*, LANGFUSE_INIT_USER_*) with dev defaults in `docker-compose.yml`
- [x] T007 [US3] Add LANGFUSE_SECRET_KEY, LANGFUSE_PUBLIC_KEY, LANGFUSE_HOST env vars to backend and telegram-bot service environments in `docker-compose.yml`
- [ ] T008 [US3] Verify: `docker compose up -d` starts all 9 containers, Langfuse UI accessible at http://localhost:3000, auto-provisioned project exists

**Checkpoint**: Langfuse UI –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è, –ø—Ä–æ–µ–∫—Ç —Å–æ–∑–¥–∞–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏, –º–æ–∂–Ω–æ –≤–æ–π—Ç–∏ —Å –ø—Ä–µ–¥–∑–∞–¥–∞–Ω–Ω—ã–º–∏ credentials

---

## Phase 3: User Story 1 ‚Äî –¢—Ä–µ–π—Å–∏–Ω–≥ LLM-–∑–∞–ø—Ä–æ—Å–æ–≤ (Priority: P1)

**Goal**: –ö–∞–∂–¥—ã–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å–æ–∑–¥–∞—ë—Ç —Ç—Ä–µ–π—Å –≤ Langfuse —Å –ø–æ–ª–Ω–æ–π –∏–µ—Ä–∞—Ä—Ö–∏–µ–π spans: LLM call ‚Üí tool calls ‚Üí response

**Independent Test**: –û—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ Telegram-–±–æ—Ç—É, –æ—Ç–∫—Ä—ã—Ç—å Langfuse UI ‚Üí Traces, –Ω–∞–π—Ç–∏ —Ç—Ä–µ–π—Å –∏ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞–ª–∏—á–∏–µ spans (LLM generation, tool execution)

### Implementation for User Story 1

- [x] T009 [US1] Replace `openai.AsyncOpenAI` import with `langfuse.openai.AsyncOpenAI` in `OpenRouterService.client` property in `backend/app/services/llm.py`
- [x] T010 [US1] Add `@observe()` decorator to `generate_agentic_response` method in `backend/app/services/sommelier.py`
- [x] T011 [US1] Add `@observe()` decorator to `execute_search_wines` and `execute_semantic_search` methods in `backend/app/services/sommelier.py`
- [x] T012 [US1] Add metadata propagation (session_id, user_id, tool_used, iterations) via `langfuse_context` or `update_current_observation` in `backend/app/services/sommelier.py`
- [ ] T013 [US1] Verify end-to-end: send Telegram message ‚Üí Langfuse UI shows trace with root span, LLM generation(s), and tool call span(s)

**Checkpoint**: –¢—Ä–µ–π—Å—ã –ø–æ—è–≤–ª—è—é—Ç—Å—è –≤ Langfuse —Å –ø–æ–ª–Ω–æ–π –∏–µ—Ä–∞—Ä—Ö–∏–µ–π spans ‚Äî LLM calls –∏ tool calls –≤–∏–¥–Ω—ã –∫–∞–∫ –¥–æ—á–µ—Ä–Ω–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã

---

## Phase 4: User Story 2 ‚Äî –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –∏ —Ç–æ–∫–µ–Ω–æ–≤ (Priority: P1)

**Goal**: Langfuse Dashboard –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ç–æ–∏–º–æ—Å—Ç—å, —Ç–æ–∫–µ–Ω—ã –∏ –ª–∞—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å LLM-–∑–∞–ø—Ä–æ—Å–æ–≤

**Independent Test**: –û—Ç–ø—Ä–∞–≤–∏—Ç—å 3-5 –∑–∞–ø—Ä–æ—Å–æ–≤ –±–æ—Ç—É, –æ—Ç–∫—Ä—ã—Ç—å Langfuse Dashboard –∏ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞–ª–∏—á–∏–µ –º–µ—Ç—Ä–∏–∫: input/output tokens, total cost, latency

### Implementation for User Story 2

- [ ] T014 [US2] Verify OpenRouter returns usage data (input_tokens, output_tokens) in LLM responses ‚Äî add logging if needed in `backend/app/services/llm.py`
- [ ] T015 [US2] Verify Langfuse Dashboard shows: total tokens, cost per trace, average latency, cost aggregation by date

**Checkpoint**: Dashboard –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç —Å—Ç–æ–∏–º–æ—Å—Ç—å –∏ —Ç–æ–∫–µ–Ω—ã ‚Äî —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫ –º–æ–∂–µ—Ç –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–∞—Å—Ö–æ–¥—ã –Ω–∞ LLM API

---

## Phase 5: User Story 4 ‚Äî –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç–≤–µ—Ç–æ–≤ (Priority: P2)

**Goal**: –†–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫ –º–æ–∂–µ—Ç —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å —Ç—Ä–µ–π—Å—ã –ø–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º –∏ –¥–æ–±–∞–≤–ª—è—Ç—å —Ä—É—á–Ω—ã–µ –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞

**Independent Test**: –û—Ç–∫—Ä—ã—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ç—Ä–µ–π—Å, –¥–æ–±–∞–≤–∏—Ç—å score –≤—Ä—É—á–Ω—É—é, –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —á—Ç–æ –æ—Ü–µ–Ω–∫–∞ —Å–æ—Ö—Ä–∞–Ω–∏–ª–∞—Å—å –∏ –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç—Å—è –≤ —Ñ–∏–ª—å—Ç—Ä–∞—Ö

### Implementation for User Story 4

- [ ] T016 [US4] Verify metadata (tool_used, iterations) appears in Langfuse trace details and is filterable
- [ ] T017 [US4] Verify manual scoring: add score to a trace via Langfuse UI, confirm it persists and appears in Dashboard

**Checkpoint**: –¢—Ä–µ–π—Å—ã —Ñ–∏–ª—å—Ç—Ä—É—é—Ç—Å—è –ø–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º, —Ä—É—á–Ω—ã–µ –æ—Ü–µ–Ω–∫–∏ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –∏ –æ—Ç–æ–±—Ä–∞–∂–∞—é—Ç—Å—è

---

## Phase 6: Polish & Cross-Cutting Concerns

**Purpose**: Resilience, persistence, and regression testing

- [ ] T018 Verify graceful degradation: stop all Langfuse containers ‚Üí send message to bot ‚Üí bot responds without errors (FR-005, SC-007)
- [ ] T019 Verify persistent storage: `docker compose down && docker compose up -d` ‚Üí previously recorded traces are preserved in Langfuse UI (FR-006, SC-006)
- [x] T020 Verify existing tests still pass after SDK changes: `cd backend && python -m pytest tests/unit/ tests/integration/ tests/contract/ -q`
- [ ] T021 Verify latency impact: compare bot response time with and without Langfuse tracing enabled (SC-005, ‚â§5% increase)

---

## Dependencies & Execution Order

### Phase Dependencies

- **Setup (Phase 1)**: No dependencies ‚Äî can start immediately
- **US3 Infrastructure (Phase 2)**: Depends on Setup ‚Äî BLOCKS all other user stories
- **US1 Tracing (Phase 3)**: Depends on US3 (Langfuse containers must be running)
- **US2 Cost Monitoring (Phase 4)**: Depends on US1 (tracing must be operational for cost data)
- **US4 Quality Analysis (Phase 5)**: Depends on US1 (tracing must produce traces with metadata)
- **Polish (Phase 6)**: Depends on all user stories being complete

### User Story Dependencies

- **User Story 3 ‚Äî Infrastructure (P1)**: Depends on Phase 1. BLOCKS all other stories (no Langfuse ‚Üí no tracing)
- **User Story 1 ‚Äî Tracing (P1)**: Depends on US3. Core SDK integration, BLOCKS US2 and US4
- **User Story 2 ‚Äî Cost Monitoring (P1)**: Depends on US1. Cost data is automatically captured by OpenAI wrapper ‚Äî mostly verification
- **User Story 4 ‚Äî Quality Analysis (P2)**: Depends on US1. Metadata filtering and manual scoring ‚Äî mostly verification

### Within Each User Story

- Configuration/dependencies FIRST (Phase 1)
- Docker infrastructure SECOND (US3)
- SDK integration THIRD (US1)
- Verification tasks LAST (US2, US4)
- Verify each checkpoint before moving on

### Parallel Opportunities

- T001, T002, T003 can run in parallel (Phase 1 ‚Äî different files)
- T016, T017 can run in parallel (Phase 5 ‚Äî independent UI verifications)
- T018, T019, T020, T021 can run in parallel (Phase 6 ‚Äî independent verification tests)

---

## Implementation Strategy

### MVP First (US3 + US1)

1. Complete Phase 1: Setup (T001-T003)
2. Complete Phase 2: US3 Infrastructure (T004-T008)
3. **STOP and VALIDATE**: `docker compose up -d` ‚Üí Langfuse UI at http://localhost:3000
4. Complete Phase 3: US1 Tracing (T009-T013)
5. **STOP and VALIDATE**: Send message ‚Üí trace appears in Langfuse UI with spans

### Incremental Delivery

1. Setup + US3 ‚Üí Langfuse running (infrastructure MVP)
2. Add US1 (Tracing) ‚Üí Full trace hierarchy visible
3. Add US2 (Cost Monitoring) ‚Üí Dashboard with costs and tokens
4. Add US4 (Quality Analysis) ‚Üí Filtering and scoring
5. Polish ‚Üí Resilience and regression verification

---

## Notes

- [P] tasks = different files, no dependencies
- [Story] label maps task to specific user story for traceability
- US3 (Infrastructure) is placed before US1 despite both being P1 ‚Äî logical dependency: containers before SDK
- US2 and US4 are mostly verification phases ‚Äî minimal code changes
- No automated tests for this feature ‚Äî it's an observability/infrastructure layer
- Commit after each task or logical group
- Stop at any checkpoint to validate story independently
