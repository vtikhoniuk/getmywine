# Feature Specification: Мониторинг LLM через Langfuse

**Feature Branch**: `017-langfuse-monitoring`
**Created**: 2026-02-10
**Status**: Draft
**Input**: Подключить Langfuse как self-hosted контейнер в Docker Compose для мониторинга LLM-запросов бэкенда

## Контекст

Сомелье-бот GetMyWine использует LLM (через OpenRouter) для рекомендаций вин с agentic RAG (tool use). Сейчас нет наблюдаемости за качеством, стоимостью и задержками LLM-запросов: неизвестно, сколько токенов тратится на запрос, какие промпты приводят к плохим результатам, как часто происходит broadening фильтров, какова реальная латентность.

Langfuse — open-source платформа для LLM observability — решает эту проблему: трейсинг вызовов, анализ стоимости, мониторинг качества, управление промптами. Self-hosted вариант позволяет хранить данные локально.

## User Scenarios & Testing *(mandatory)*

### User Story 1 — Трейсинг LLM-запросов (Priority: P1)

Разработчик открывает Langfuse UI и видит полный трейс каждого запроса пользователя: от входящего сообщения через выбор инструмента (search_wines / semantic_search) до финального ответа, включая промежуточные tool calls.

**Why this priority**: Без трейсинга невозможно диагностировать проблемы качества — разработчик не видит, что именно пошло не так в цепочке вызовов.

**Independent Test**: Отправить запрос боту, открыть Langfuse UI, найти трейс по имени/ID и проверить наличие всех spans (LLM call, tool execution, response formatting).

**Acceptance Scenarios**:

1. **Given** пользователь отправляет сообщение боту, **When** запрос обрабатывается, **Then** в Langfuse появляется трейс с именем, содержащим текст запроса
2. **Given** LLM вызывает инструмент (search_wines), **When** инструмент выполняется, **Then** в трейсе отображается span с именем инструмента, входными параметрами и результатом
3. **Given** agentic loop выполняет 2 итерации (первый поиск → broadening → второй поиск), **When** трейс открыт, **Then** видны оба вызова инструментов как отдельные spans

---

### User Story 2 — Мониторинг стоимости и токенов (Priority: P1)

Разработчик анализирует в Langfuse Dashboard стоимость LLM-запросов: общее количество токенов (input/output), стоимость по модели, средняя стоимость одного запроса пользователя.

**Why this priority**: Без мониторинга стоимости невозможно контролировать бюджет на LLM API — один неоптимальный промпт может кратно увеличить расходы.

**Independent Test**: Отправить 5 запросов боту, открыть Langfuse Dashboard и проверить, что отображаются: общие токены, стоимость, средняя латентность.

**Acceptance Scenarios**:

1. **Given** бот обработал запрос, **When** разработчик открывает Dashboard, **Then** видны метрики: input tokens, output tokens, total cost, latency
2. **Given** за день было обработано N запросов, **When** разработчик фильтрует по дате, **Then** видна суммарная стоимость и среднее время ответа

---

### User Story 3 — Langfuse как часть инфраструктуры (Priority: P1)

Разработчик запускает `docker compose up` и получает работающую систему с Langfuse, без ручной настройки — все контейнеры стартуют автоматически, Langfuse подключается к своей БД, UI доступен по URL.

**Why this priority**: Если Langfuse требует ручной настройки, его не будут использовать — интеграция должна быть zero-config.

**Independent Test**: Выполнить `docker compose up -d`, дождаться старта, открыть Langfuse UI в браузере и убедиться, что страница загружается.

**Acceptance Scenarios**:

1. **Given** разработчик выполняет `docker compose up -d`, **When** все контейнеры стартуют, **Then** Langfuse UI доступен по HTTP
2. **Given** Langfuse запущен впервые, **When** разработчик открывает UI, **Then** можно создать аккаунт и проект без внешних зависимостей
3. **Given** контейнеры перезапускаются, **When** Langfuse стартует повторно, **Then** все ранее собранные трейсы сохранены (persistent storage)

---

### User Story 4 — Анализ качества ответов (Priority: P2)

Разработчик использует Langfuse для анализа качества: просматривает конкретные трейсы, ставит оценки (scores) отдельным ответам, фильтрует по метаданным (тип запроса, выбранный инструмент).

**Why this priority**: Оценка качества важна для улучшения промптов, но базовый трейсинг и мониторинг стоимости более приоритетны.

**Independent Test**: Открыть конкретный трейс, добавить вручную оценку (score), убедиться что оценка сохранилась и отображается в фильтрах.

**Acceptance Scenarios**:

1. **Given** трейс отображается в Langfuse, **When** разработчик добавляет score, **Then** оценка привязана к трейсу и отображается в Dashboard
2. **Given** трейсы содержат метаданные (тип инструмента), **When** разработчик фильтрует по метаданным, **Then** отображаются только соответствующие трейсы

---

### Edge Cases

- Что происходит, если Langfuse недоступен? → Бот продолжает работать без мониторинга; ошибки отправки трейсов логируются, но не блокируют ответ пользователю
- Что происходит при большом объёме запросов? → Langfuse SDK отправляет данные асинхронно и батчами, не влияя на латентность ответа
- Что происходит, если Langfuse-контейнер не стартует? → Остальные контейнеры (backend, telegram-bot, db) работают независимо
- Что происходит при обновлении Langfuse? → Данные сохраняются в persistent volumes; обновление через pull нового образа
- Что происходит, если Langfuse занимает слишком много ресурсов? → Можно установить лимиты ресурсов на контейнеры и настроить retention policy для старых трейсов

## Requirements *(mandatory)*

### Functional Requirements

- **FR-001**: Система ДОЛЖНА автоматически записывать трейс для каждого запроса пользователя, включая: входящее сообщение, вызовы LLM, вызовы инструментов (tool calls), финальный ответ
- **FR-002**: Каждый трейс ДОЛЖЕН содержать: input/output tokens, стоимость (cost), латентность (duration), имя модели
- **FR-003**: Tool calls (search_wines, semantic_search) ДОЛЖНЫ отображаться как отдельные spans внутри трейса с входными параметрами и результатами
- **FR-004**: Langfuse ДОЛЖЕН запускаться как часть `docker compose up` без дополнительных ручных шагов
- **FR-005**: Отказ Langfuse НЕ ДОЛЖЕН влиять на работу бота — мониторинг является non-blocking
- **FR-006**: Данные трейсов ДОЛЖНЫ сохраняться между перезапусками контейнеров (persistent storage)
- **FR-007**: Langfuse UI ДОЛЖЕН быть доступен по HTTP для просмотра трейсов и дашбордов
- **FR-008**: Система ДОЛЖНА передавать метаданные в трейсы: тип запроса, выбранный инструмент, количество итераций agent loop
- **FR-009**: Интеграция НЕ ДОЛЖНА увеличивать латентность ответа бота более чем на 5% (асинхронная отправка)

### Key Entities

- **Trace**: Полный путь обработки одного запроса пользователя — от получения сообщения до отправки ответа
- **Span**: Отдельный шаг внутри трейса — вызов LLM, выполнение инструмента, генерация embedding
- **Generation**: Конкретный вызов LLM с промптом и ответом, токенами и стоимостью
- **Score**: Оценка качества трейса — ручная (разработчик) или автоматическая (метрика)

## Success Criteria *(mandatory)*

### Measurable Outcomes

- **SC-001**: 100% запросов пользователей создают трейс в Langfuse (при доступности Langfuse)
- **SC-002**: Каждый трейс содержит >= 2 spans: минимум 1 LLM generation + 1 tool call
- **SC-003**: Dashboard показывает суммарную стоимость и количество токенов за выбранный период
- **SC-004**: Langfuse UI загружается после `docker compose up` без ручной настройки
- **SC-005**: Латентность ответа бота увеличивается не более чем на 5% при включённом мониторинге
- **SC-006**: Данные трейсов сохраняются после `docker compose down && docker compose up`
- **SC-007**: При недоступности Langfuse бот отвечает пользователю без ошибок

## Assumptions

- Langfuse self-hosted версия поддерживает все необходимые функции (трейсинг, стоимость, dashboard)
- Self-hosted Langfuse требует собственный PostgreSQL (отдельный от основной БД приложения), ClickHouse и Redis
- Текущий сервер имеет достаточно ресурсов для дополнительных контейнеров (рекомендуется 4+ ядра, 16GB+ RAM)
- Langfuse SDK совместим с текущим LLM-провайдером (OpenRouter с OpenAI-совместимым API)
- Трейсы отправляются асинхронно и не блокируют основной поток обработки запросов

## Scope Boundaries

**Включено**:
- Добавление контейнеров Langfuse в docker-compose.yml
- Интеграция SDK в бэкенд (SommelierService, LLMService)
- Трейсинг LLM-запросов с tool calls
- Мониторинг стоимости и токенов
- Ручная оценка качества через UI

**Исключено**:
- Автоматическая оценка качества (LLM-as-judge)
- Prompt management через Langfuse (версионирование промптов)
- Алерты и уведомления при проблемах качества
- A/B тестирование промптов
- Интеграция с внешними системами мониторинга (Grafana, Datadog)
- Production deployment (SSL, домен, авторизация) — только dev-окружение
